{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample and Save Locally\n",
    "* using SimpleITK and numpy to preprocess each nifti image and save them in a local directory\n",
    "    * resample -> normalize\n",
    "* __Can possibly add bias correction and multiprocessing capabilities in?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from io_func import resample_img, get_multi_class_labels, normalize_clip, to_channels_first, convert_4D_to_3D\n",
    "from SimpleITK import GetImageFromArray, GetArrayFromImage, ReadImage\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "import time\n",
    "#from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    '''decorator for timing'''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print ('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PreprocessLocal(object):\n",
    "    '''Preprocesses 3D/4D nifti images and saves it locally compressed for the Medical Segmentation Decathlon Challenge for one task or a directory of images\n",
    "    Static Methods:\n",
    "    * create_new_dir: creates a new directory in the competition format \n",
    "    * preprocess_fn_and_save: applies a function to each image (nii or npz) in a specific directory, such as //imagesTr\n",
    "    '''\n",
    "    def __init__(self, data_path, output_path, num_classes=4):\n",
    "        # specificies the path to //Task0_\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.num_classes = num_classes\n",
    "        # gets list of file names for saving the files; NOTE THAT filenames are the same for training images and labels\n",
    "        for root, dirs, files in os.walk(self.data_path + '\\\\imagesTr\\\\'):\n",
    "            filenames = [file[:-4] for file in files if file.endswith(\".nii\")]\n",
    "        self.filenames = filenames\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_new_dir(output_path, data_path = None):\n",
    "        '''\n",
    "        Used to create a directory in the challenge format\n",
    "        param output_path: path to new folder\n",
    "        param data_path: path to original file location (task folder)\n",
    "        '''\n",
    "        os.mkdir(output_path)\n",
    "        # 2 subdirectories\n",
    "        os.mkdir(os.path.join(output_path, 'imagesTr'))\n",
    "        os.mkdir(os.path.join(output_path, 'labelsTr'))\n",
    "        if isinstance(data_path, (basestring, str, unicode)): \n",
    "            copyfile(data_path + '\\\\dataset.json', output_path +'\\\\dataset.json')\n",
    "        print('Directory: ' + output_path + ' created.')\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_fn_and_save(data_path, output_path, file_type, fn, fn_args):\n",
    "        '''\n",
    "        general function to preprocesses all files within a specific directory with a function that you specify\n",
    "        ***NOTE: the data_path you need to specify here is different from the self.data_path one.\n",
    "            must be a single specific directory, such as //imagesTr instead of the task folder\n",
    "        param data_path: specific data directory to preprocess\n",
    "        param output_path: specific directory to save the data\n",
    "        param file_type: type of the files you want to preprocess (nii or npz)\n",
    "        param fn: function you want to apply\n",
    "        param fn_args: dictionary of arguments for the function\n",
    "        '''\n",
    "        if file_type == 'nii':\n",
    "            for root, dirs, files in os.walk(data_path):\n",
    "                filenames = [file[:-4] for file in files if file.endswith(\".nii\")]\n",
    "            images_list = glob(data_path + '*.nii', recursive=True)\n",
    "        elif file_type == 'npz':\n",
    "            for root, dirs, files in os.walk(data_path):\n",
    "                filenames = [file[:-4] for file in files if file.endswith(\".npz\")]\n",
    "            images_list = glob(data_path + '*.npz', recursive=True)\n",
    "        # checking to make sure there's a save directory\n",
    "        if os.path.exists(output_path) == False:\n",
    "            os.mkdir(output_path)\n",
    "            print('Directory: ' + output_path + ' created.')\n",
    "        # apply the function to each image in the directory and save them.\n",
    "        for idx, image in enumerate(images_list):\n",
    "        # need to save with file names\n",
    "            np.savez_compressed(output_path + filenames[idx] , fn(image, file_type = file_type, **fn_args))\n",
    "        print('Finished preprocessing and saving '+ str(len(images_list)) + ' files.')\n",
    "        \n",
    "    @timeit\n",
    "    def preprocess(self, path, is_label = False):\n",
    "        '''\n",
    "        resamples nifti image to 1 mm isotropic spacing\n",
    "        param path: path to a 3D/4D nifti1image image\n",
    "        param is_label: Boolean representing whether or not the image is a label\n",
    "        returns: a preprocessed numpy array\n",
    "        '''\n",
    "           \n",
    "        sitk_read = ReadImage(path)\n",
    "        # if label\n",
    "        if is_label: \n",
    "            itk_label = GetArrayFromImage(resample_img(sitk_read, is_label=True))\n",
    "            y = get_multi_class_labels(np.expand_dims(itk_label,1), self.num_classes)\n",
    "            return y\n",
    "        \n",
    "        elif sitk_read.GetDimension() == 3:\n",
    "            return normalize_clip(GetArrayFromImage(resample_img(sitk_read)))\n",
    "                \n",
    "        elif sitk_read.GetDimension() == 4:\n",
    "            np_list = convert_4D_to_3D(sitk_read) \n",
    "            # resample each array\n",
    "            resample_list = [GetArrayFromImage(resample_img(arr)) for arr in np_list]\n",
    "\n",
    "            return normalize_clip(np.stack(resample_list, axis = 1))\n",
    "        \n",
    "    @timeit\n",
    "    def preprocess_and_save(self):\n",
    "        '''\n",
    "        applies resampling and normalization of regular images and labels and saves the images.\n",
    "        [original MSD Nifti1 images]\n",
    "        ***Arguments are specified when initializing class.\n",
    "        '''\n",
    "        # gets lists of paths to images\n",
    "        images_list = glob(self.data_path + '\\\\imagesTr\\\\*.nii', recursive=True)\n",
    "        labels_list = glob(self.data_path + '\\\\labelsTr\\\\*.nii', recursive=True)\n",
    "        # checking to make sure there's a save directory\n",
    "        if os.path.exists(self.output_path) == False:\n",
    "            PreprocessLocal.create_new_dir(self.output_path, self.data_path)\n",
    "        # preprocess each image and save them.\n",
    "        for (idx, image), label in zip(enumerate(images_list), labels_list):\n",
    "        # need to save with file names\n",
    "            np.savez_compressed(output_path + '\\\\imagesTr\\\\' + self.filenames[idx] , self.preprocess(image))\n",
    "            np.savez_compressed(output_path + '\\\\labelsTr\\\\' + self.filenames[idx] , self.preprocess(label, is_label = True)) \n",
    "        print('Finished preprocessing and saving '+ str(len(images_list)) + ' files.')\n",
    "        ############ WORKS IN PROGRESS\n",
    "    ## SEPARATING preprocessing for multiprocessing\n",
    "    def preprocess_regular(self):\n",
    "        if os.path.exists(self.output_path) == False:\n",
    "            PreprocessLocal.create_new_dir(self.output_path, self.data_path)\n",
    "        images_list = glob(self.data_path + '\\\\imagesTr\\\\*.nii', recursive=True)\n",
    "        for idx, image in enumerate(images_list):\n",
    "        # need to save with file names\n",
    "            np.savez_compressed(output_path + '\\\\imagesTr\\\\' + self.filenames[idx] , self.preprocess(image))\n",
    "        print(\"Finished preprocessing \" + str(len(images_list)) + ' files.')    \n",
    "        \n",
    "    def preprocess_labels(self):\n",
    "        if os.path.exists(self.output_path) == False:\n",
    "            PreprocessLocal.create_new_dir(self.output_path, self.data_path)\n",
    "        labels_list = glob(self.data_path + '\\\\labelsTr\\\\*.nii', recursive=True)\n",
    "        for idx, label in enumerate(labels_list):\n",
    "        # need to save with file names\n",
    "            np.savez_compressed(output_path + '\\\\labelsTr\\\\' + self.filenames[idx] , self.preprocess(label, is_label = True)) \n",
    "        print(\"Finished preprocessing \" + str(len(labels_list)) + ' files.')    \n",
    "\n",
    "    def run_processes(self):\n",
    "        # I want each process to do the preprocessing for a separate image\n",
    "        n_workers = mp.cpu_count()\n",
    "        p_reg = mp.Process(target = self.preprocess_regular)\n",
    "        p_lab = mp.Process(target = self.preprocess_labels )\n",
    "        p_reg.start()\n",
    "        p_lab.start()\n",
    "#         print('Done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.reddit.com/r/learnpython/comments/3ptclb/how_to_take_advantage_of_multiple_cores_inside_a/\n",
    "<br> https://stackoverflow.com/questions/40097485/how-to-use-multiprocessing-in-python-within-a-class\n",
    "* why doesn't it return shit in idle? **Test if it returns in python interpretor and check niftynet implementations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Wall time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "# #### preprocess_and_save()\n",
    "# data_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\MSD_raw\\\\Task02_Heart'#MSD_raw\\\\Task02_Heart\n",
    "# output_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\Heart_Preprocessed'\n",
    "# saver = PreprocessLocal(data_path, output_path, num_classes = 2)\n",
    "# %time saver.run_processes() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'preprocess'  11829.66 ms\n",
      "'preprocess'  626.04 ms\n",
      "'preprocess'  13049.73 ms\n",
      "'preprocess'  509.03 ms\n",
      "'preprocess'  12961.72 ms\n",
      "'preprocess'  689.04 ms\n",
      "'preprocess'  20252.13 ms\n",
      "'preprocess'  728.04 ms\n",
      "'preprocess'  10940.61 ms\n",
      "'preprocess'  571.03 ms\n",
      "'preprocess'  13505.75 ms\n",
      "'preprocess'  667.04 ms\n",
      "'preprocess'  13305.74 ms\n",
      "'preprocess'  789.04 ms\n",
      "'preprocess'  14826.82 ms\n",
      "'preprocess'  1700.09 ms\n",
      "'preprocess'  12555.70 ms\n",
      "'preprocess'  780.04 ms\n",
      "'preprocess'  20145.13 ms\n",
      "'preprocess'  1035.06 ms\n",
      "'preprocess'  21317.19 ms\n",
      "'preprocess'  1084.06 ms\n",
      "'preprocess'  17617.98 ms\n",
      "'preprocess'  861.05 ms\n",
      "'preprocess'  18788.05 ms\n",
      "'preprocess'  780.05 ms\n",
      "'preprocess'  14522.81 ms\n",
      "'preprocess'  736.04 ms\n",
      "'preprocess'  13912.78 ms\n",
      "'preprocess'  784.04 ms\n",
      "'preprocess'  12448.70 ms\n",
      "'preprocess'  677.04 ms\n",
      "'preprocess'  13642.76 ms\n",
      "'preprocess'  704.04 ms\n",
      "'preprocess'  13562.76 ms\n",
      "'preprocess'  837.05 ms\n",
      "'preprocess'  15232.85 ms\n",
      "'preprocess'  672.04 ms\n",
      "'preprocess'  12920.72 ms\n",
      "'preprocess'  648.04 ms\n",
      "Finished preprocessing and saving 20 files.\n",
      "'preprocess_and_save'  511197.54 ms\n"
     ]
    }
   ],
   "source": [
    "#### preprocess_and_save()\n",
    "data_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\MSD_raw\\\\Task02_Heart'#MSD_raw\\\\Task02_Heart\n",
    "output_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\Heart_Preprocessed'\n",
    "saver = PreprocessLocal(data_path, output_path, num_classes = 2)\n",
    "saver.preprocess_and_save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PreprocessLocal.preprocess_fn_and_save(...)\n",
    "############# ADD FUNCTIONALITY TO ALLOW FOR CHANNELS FIRST DATA\n",
    "d_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\mexican'\n",
    "o_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\test'\n",
    "from io_func import N4_bias_correction\n",
    "def bias_corection(image_path, file_type, channels_format = 'channels_first', n_channels = 4):\n",
    "    # loading files\n",
    "    if file_type == 'nii':\n",
    "        image = ReadImage(image_path)\n",
    "    elif file_type == 'npz'\n",
    "        image = GetImageFromArray(np.load(image_path)['array_0'].squeeze())\n",
    "    # applying bias correction\n",
    "    if image.GetDimension == 4: \n",
    "        np_list = convert_4D_to_3D(image) \n",
    "        # resample each array\n",
    "        corrected_list = [GetArrayFromImage(N4_bias_correction(arr)) for arr in np_list]\n",
    "        return np.stack(resample_list, axis = 1)\n",
    "    if image.GetDimension == 3:\n",
    "        return GetArrayFromImage(N4_bias_correction(image))\n",
    "saver.preprocess_fn_and_save(d_path, o_path, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_func import resample_img, get_multi_class_labels, normalize_clip, to_channels_first, convert_4D_to_3D\n",
    "from SimpleITK import GetImageFromArray, GetArrayFromImage, ReadImage\n",
    "import unittest\n",
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_N4_bias_correction (__main__.TestLocalPreproccesingShapes) ... ERROR\n",
      "test_preprocess_3D (__main__.TestLocalPreproccesingShapes) ... skipped 'already works so skipping'\n",
      "test_preprocess_4D (__main__.TestLocalPreproccesingShapes) ... skipped 'already works so skipping'\n",
      "test_preprocess_labels (__main__.TestLocalPreproccesingShapes) ... skipped 'already works so skipping'\n",
      "test_transpose_output_and_N4_BiasCorrection (__main__.TestLocalPreproccesingShapes) ... skipped 'does not work'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_N4_bias_correction (__main__.TestLocalPreproccesingShapes)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-20-6ae7fc094076>\", line 63, in test_N4_bias_correction\n",
      "    bias_correction = sitk.N4BiasFieldCorrection(itk_image, img_mask)\n",
      "  File \"C:\\Users\\Joseph\\Miniconda3\\envs\\ml\\lib\\site-packages\\SimpleITK\\SimpleITK.py\", line 51318, in N4BiasFieldCorrection\n",
      "    return _SimpleITK.N4BiasFieldCorrection(*args)\n",
      "RuntimeError: Exception thrown in SimpleITK N4BiasFieldCorrection: c:\\d\\vs14-win64-pkg\\simpleitk-build\\itk-prefix\\include\\itk-4.13\\itkImageToImageFilter.hxx:241:\n",
      "itk::ERROR: SubtractImageFilter(0000001C17012B20): Inputs do not occupy the same physical space! \n",
      "InputImage Origin: [0.0000000e+00, 0.0000000e+00, 0.0000000e+00], InputImage_1 Origin: [-3.9900000e+02, -3.9900000e+02, -1.7700000e+02]\n",
      "\tTolerance: 1.0000000e-06\n",
      "InputImage Spacing: [1.0000000e+00, 1.0000000e+00, 1.0000000e+00], InputImage_1 Spacing: [3.9900000e+02, 3.9900000e+02, 1.7700000e+02]\n",
      "\tTolerance: 1.0000000e-06\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 1239.798s\n",
      "\n",
      "FAILED (errors=1, skipped=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1c00482128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestLocalPreproccesingShapes(unittest.TestCase):\n",
    "    '''\n",
    "    tests the shapes for each step of the local preprocessing pipeline\n",
    "    '''\n",
    "    def setUp(self):\n",
    "        base_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\MSD_raw\\\\'\n",
    "        self.data_path_4D = base_path + 'Task01_BrainTumour\\\\imagesTr\\\\BRATS_001.nii'\n",
    "        self.data_path_3D = base_path + 'Task02_Heart\\\\imagesTr\\\\la_003.nii'\n",
    "        self.label_path = base_path + 'Task01_BrainTumour\\\\labelsTr\\\\BRATS_001.nii'\n",
    "        \n",
    "    @unittest.skip(\"already works so skipping\")      \n",
    "    def test_preprocess_3D(self):\n",
    "        '''\n",
    "        tests to make sure that 3D preprocessing output shapes are correct\n",
    "        '''\n",
    "        sitk_read = ReadImage(self.data_path_3D)\n",
    "        preprocessed = normalize_clip(GetArrayFromImage(resample_img(sitk_read)))\n",
    "        self.assertEqual(preprocessed.shape, (178,400,400))\n",
    "        \n",
    "    @unittest.skip(\"already works so skipping\")      \n",
    "    def test_preprocess_4D(self):\n",
    "        '''\n",
    "        tests to make sure that 4D preprocessing output shapes are correct\n",
    "        '''\n",
    "        num_classes = 4\n",
    "        sitk_read = ReadImage(self.data_path_4D)\n",
    "        # converts to list of 3D arrays\n",
    "        np_list = convert_4D_to_3D(sitk_read) \n",
    "        # resample each array\n",
    "        resample_list = [GetArrayFromImage(resample_img(arr)) for arr in np_list]\n",
    "        preprocessed = normalize_clip(np.stack(resample_list, axis = 1))\n",
    "        self.assertEqual(preprocessed.shape, (155,4,240,240))\n",
    "    \n",
    "    @unittest.skip(\"already works so skipping\")      \n",
    "    def test_preprocess_labels(self):\n",
    "        '''\n",
    "        tests to make sure that label shapes are correct\n",
    "        '''\n",
    "        num_classes = 4\n",
    "        sitk_read = ReadImage(self.label_path)\n",
    "        itk_label = GetArrayFromImage(resample_img(sitk_read, is_label=True))\n",
    "        y = get_multi_class_labels(np.expand_dims(itk_label,1), n_labels = num_classes)\n",
    "        self.assertEqual(y.shape, (155,4,240,240))   \n",
    "    \n",
    "    def test_N4_bias_correction(self):\n",
    "        '''\n",
    "        tests the N4_bias_correction function from io_func\n",
    "        '''\n",
    "        # importing data and verifying dimensions + spacing\n",
    "        d_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\Heart_Preprocessed'\n",
    "        arr = np.load(d_path + '\\\\imagesTr\\\\la_003.npz')['arr_0']\n",
    "        itk_image = GetImageFromArray(arr)\n",
    "        self.assertEqual(itk_image.GetSize(), (400,400,178))\n",
    "        self.assertEqual(itk_image.GetSpacing(), (1.0, 1.0, 1.0))\n",
    "        itk_image = sitk.Cast(itk_image,sitk.sitkFloat32)\n",
    "        \n",
    "        img_mask = sitk.Cast(sitk.BinaryNot(sitk.BinaryThreshold(itk_image, 0, 0)), sitk.sitkUInt8)\n",
    "        self.assertEqual(img_mask.GetSize(), itk_image.GetSize())\n",
    "        self.assertEqual(img_mask.GetSpacing(), itk_image.GetSpacing())\n",
    "        self.assertEqual(img_mask.GetOrigin(), itk_image.GetOrigin())\n",
    "        self.assertEqual(img_mask.GetDirection(), itk_image.GetDirection())\n",
    "            \n",
    "        bias_correction = sitk.N4BiasFieldCorrection(itk_image, img_mask)\n",
    "        self.assertEqual(GetArrayFromImage(bias_correction).shape, (178,400,400))\n",
    "        \n",
    "    @unittest.skip('does not work')\n",
    "    def test_transpose_output_and_N4_BiasCorrection(self):\n",
    "        d_path = 'C:\\\\Users\\\\Joseph\\\\MSD\\\\Heart_Preprocessed'\n",
    "        arr = np.load(d_path + '\\\\imagesTr\\\\la_003.npz')['arr_0']\n",
    "        arr_labels = np.load(d_path + '\\\\labelsTr\\\\la_003.npz')['arr_0']\n",
    "        self.assertEqual(np.transpose(np.expand_dims(arr,1), [1,0,2,3]).shape, (1,178,400,400))\n",
    "        self.assertEqual(arr_labels.shape, (178, 2, 400,400))\n",
    "        \n",
    "        from io_func import N4_bias_correction\n",
    "        itk_image = GetImageFromArray(arr)\n",
    "        self.assertEqual(itk_image.GetSize(), (400,400,178))\n",
    "        bias_correction = GetArrayFromImage(N4_bias_correction(itk_image))\n",
    "        self.assertEqual(bias_correction.shape, (178,400,400))\n",
    "                       \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
